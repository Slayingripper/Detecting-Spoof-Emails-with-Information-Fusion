[34m[1mwandb[0m: [33mWARNING[0m wandb.init() arguments ignored because wandb magic has already been initialized
Reading GloVe: 0it [00:00, ?it/s]Reading GloVe: 3005it [00:00, 30048.74it/s]Reading GloVe: 6144it [00:00, 30438.85it/s]Reading GloVe: 9563it [00:00, 31473.47it/s]Reading GloVe: 13337it [00:00, 32753.87it/s]Reading GloVe: 17198it [00:00, 34313.82it/s]Reading GloVe: 21283it [00:00, 36042.46it/s]Reading GloVe: 25284it [00:00, 37146.02it/s]Reading GloVe: 28793it [00:00, 35974.94it/s]Reading GloVe: 32606it [00:00, 36593.46it/s]Reading GloVe: 36644it [00:01, 37651.93it/s]Reading GloVe: 40385it [00:01, 37578.06it/s]Reading GloVe: 44382it [00:01, 38262.87it/s]Reading GloVe: 48474it [00:01, 39022.00it/s]Reading GloVe: 52416it [00:01, 38359.34it/s]Reading GloVe: 56368it [00:01, 38698.73it/s]Reading GloVe: 60234it [00:01, 37434.60it/s]Reading GloVe: 63984it [00:01, 36945.89it/s]Reading GloVe: 68017it [00:01, 37899.63it/s]Reading GloVe: 72082it [00:01, 38684.28it/s]Reading GloVe: 76172it [00:02, 39322.95it/s]Reading GloVe: 80239it [00:02, 39717.53it/s]Reading GloVe: 84299it [00:02, 39977.58it/s]Reading GloVe: 88303it [00:02, 39756.36it/s]Reading GloVe: 92340it [00:02, 39937.03it/s]Reading GloVe: 96400it [00:02, 40133.14it/s]Reading GloVe: 100483it [00:02, 40337.73it/s]Reading GloVe: 104519it [00:02, 38908.20it/s]Reading GloVe: 108569it [00:02, 39371.20it/s]Reading GloVe: 112525it [00:02, 39427.60it/s]Reading GloVe: 116526it [00:03, 39600.07it/s]Reading GloVe: 120575it [00:03, 38179.51it/s]Reading GloVe: 124487it [00:03, 38454.26it/s]Reading GloVe: 128344it [00:03, 38370.34it/s]Reading GloVe: 132189it [00:03, 36890.46it/s]Reading GloVe: 136219it [00:03, 37850.03it/s]Reading GloVe: 140241it [00:03, 38528.73it/s]Reading GloVe: 144288it [00:03, 39089.12it/s]Reading GloVe: 148210it [00:03, 38216.53it/s]Reading GloVe: 152233it [00:03, 38796.45it/s]Reading GloVe: 156257it [00:04, 39217.38it/s]Reading GloVe: 160236it [00:04, 39386.30it/s]Reading GloVe: 164220it [00:04, 39520.18it/s]Reading GloVe: 168248it [00:04, 39744.80it/s]Reading GloVe: 172243it [00:04, 39804.59it/s]Reading GloVe: 176227it [00:04, 38938.16it/s]Reading GloVe: 180293it [00:04, 39437.13it/s]Reading GloVe: 184346it [00:04, 39758.40it/s]Reading GloVe: 188327it [00:04, 39498.51it/s]Reading GloVe: 192342it [00:04, 39690.56it/s]Reading GloVe: 196314it [00:05, 38528.93it/s]Reading GloVe: 200310it [00:05, 38944.34it/s]Reading GloVe: 204295it [00:05, 39211.17it/s]Reading GloVe: 208222it [00:05, 39197.61it/s]Reading GloVe: 212258it [00:05, 39537.73it/s]Reading GloVe: 216241it [00:05, 39622.35it/s]Reading GloVe: 220206it [00:05, 39309.77it/s]Reading GloVe: 224140it [00:05, 38164.46it/s]Reading GloVe: 228009it [00:05, 38318.21it/s]Reading GloVe: 231977it [00:06, 38712.30it/s]Reading GloVe: 236010it [00:06, 39181.63it/s]Reading GloVe: 239974it [00:06, 39314.69it/s]Reading GloVe: 243966it [00:06, 39492.82it/s]Reading GloVe: 247970it [00:06, 39654.79it/s]Reading GloVe: 251962it [00:06, 39730.85it/s]Reading GloVe: 255993it [00:06, 39901.81it/s]Reading GloVe: 260023it [00:06, 40019.25it/s]Reading GloVe: 264026it [00:06, 40020.63it/s]Reading GloVe: 268030it [00:06, 40024.33it/s]Reading GloVe: 272033it [00:07, 40014.57it/s]Reading GloVe: 276046it [00:07, 40048.48it/s]Reading GloVe: 280063it [00:07, 40082.55it/s]Reading GloVe: 284072it [00:07, 40073.48it/s]Reading GloVe: 288080it [00:07, 40052.04it/s]Reading GloVe: 292095it [00:07, 40081.28it/s]Reading GloVe: 296104it [00:07, 40048.59it/s]Reading GloVe: 300109it [00:07, 39912.71it/s]Reading GloVe: 304101it [00:07, 39872.54it/s]Reading GloVe: 308137it [00:07, 40015.67it/s]Reading GloVe: 312144it [00:08, 40030.25it/s]Reading GloVe: 316159it [00:08, 40065.71it/s]Reading GloVe: 320166it [00:08, 39822.30it/s]Reading GloVe: 324171it [00:08, 39888.90it/s]Reading GloVe: 328173it [00:08, 39927.70it/s]Reading GloVe: 332192it [00:08, 40001.31it/s]Reading GloVe: 336193it [00:08, 39933.70it/s]Reading GloVe: 340187it [00:08, 39913.88it/s]Reading GloVe: 344179it [00:08, 39552.04it/s]Reading GloVe: 348166it [00:08, 39646.77it/s]Reading GloVe: 352132it [00:09, 37751.62it/s]Reading GloVe: 356183it [00:09, 38537.05it/s]Reading GloVe: 360197it [00:09, 39002.85it/s]Reading GloVe: 364207it [00:09, 39323.05it/s]Reading GloVe: 368217it [00:09, 39552.10it/s]Reading GloVe: 372186it [00:09, 39590.90it/s]Reading GloVe: 376152it [00:09, 39609.24it/s]Reading GloVe: 380190it [00:09, 39836.75it/s]Reading GloVe: 384177it [00:09, 37933.25it/s]Reading GloVe: 388186it [00:09, 38554.12it/s]Reading GloVe: 392163it [00:10, 38909.52it/s]Reading GloVe: 396207it [00:10, 39354.67it/s]Reading GloVe: 400000it [00:10, 39006.46it/s]
2020-02-18 12:04:12.559883: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-18 12:04:12.582772: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494395000 Hz
2020-02-18 12:04:12.583190: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b0d450 executing computations on platform Host. Devices:
2020-02-18 12:04:12.583248: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-18 12:04:12.588594: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-02-18 12:04:12.596274: W tensorflow/core/framework/allocator.cc:107] Allocation of 85069600 exceeds 10% of system memory.
2020-02-18 12:04:12.792222: W tensorflow/core/framework/allocator.cc:107] Allocation of 85069600 exceeds 10% of system memory.
2020-02-18 12:04:12.835597: W tensorflow/core/framework/allocator.cc:107] Allocation of 85069600 exceeds 10% of system memory.
tracking <tf.Variable 'Variable:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_1:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_2:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_3:0' shape=() dtype=int32> fn
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_1 (Embedding)      (None, 100, 100)          21267400  
_________________________________________________________________
lstm_1 (LSTM)                (None, 128)               117248    
_________________________________________________________________
dropout_1 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 2)                 258       
=================================================================
Total params: 21,384,906
Trainable params: 117,506
Non-trainable params: 21,267,400
_________________________________________________________________
X_train.shape: (225000, 100)
X_test.shape: (75000, 100)
y_train.shape: (225000, 2)
y_test.shape: (75000, 2)
WARNING:tensorflow:From /home/blackfalcon/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/blackfalcon/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Train on 225000 samples, validate on 75000 samples
WARNING:tensorflow:From /home/blackfalcon/.local/lib/python3.7/site-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:From /home/blackfalcon/.local/lib/python3.7/site-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

Epoch 1/20
2020-02-18 12:04:15.172257: W tensorflow/core/framework/allocator.cc:107] Allocation of 85069600 exceeds 10% of system memory.
2020-02-18 12:04:15.196316: W tensorflow/core/framework/allocator.cc:107] Allocation of 40960000 exceeds 10% of system memory.
  1024/225000 [..............................] - ETA: 7:09 - loss: 0.6778 - accuracy: 0.6240 - precision: 0.4477 - recall: 0.8271  2048/225000 [..............................] - ETA: 6:09 - loss: 0.6715 - accuracy: 0.6602 - precision: 0.4621 - recall: 0.8473  3072/225000 [..............................] - ETA: 5:44 - loss: 0.6627 - accuracy: 0.6901 - precision: 0.4713 - recall: 0.8662  4096/225000 [..............................] - ETA: 5:31 - loss: 0.6532 - accuracy: 0.7126 - precision: 0.4797 - recall: 0.8801  5120/225000 [..............................] - ETA: 5:20 - loss: 0.6442 - accuracy: 0.7283 - precision: 0.4876 - recall: 0.8913  6144/225000 [..............................] - ETA: 5:15 - loss: 0.6346 - accuracy: 0.7401 - precision: 0.4943 - recall: 0.8997  7168/225000 [..............................] - ETA: 5:10 - loss: 0.6245 - accuracy: 0.7487 - precision: 0.5012 - recall: 0.9063  8192/225000 [>.............................] - ETA: 5:06 - loss: 0.6143 - accuracy: 0.7560 - precision: 0.5076 - recall: 0.9113  9216/225000 [>.............................] - ETA: 5:03 - loss: 0.6044 - accuracy: 0.7610 - precision: 0.5138 - recall: 0.9149 10240/225000 [>.............................] - ETA: 5:00 - loss: 0.5939 - accuracy: 0.7686 - precision: 0.5201 - recall: 0.9160 11264/225000 [>.............................] - ETA: 4:58 - loss: 0.5834 - accuracy: 0.7792 - precision: 0.5265 - recall: 0.9139 12288/225000 [>.............................] - ETA: 4:56 - loss: 0.5710 - accuracy: 0.7846 - precision: 0.5322 - recall: 0.9081 13312/225000 [>.............................] - ETA: 4:54 - loss: 0.5621 - accuracy: 0.7834 - precision: 0.5371 - recall: 0.8984 14336/225000 [>.............................] - ETA: 4:52 - loss: 0.5518 - accuracy: 0.7891 - precision: 0.5417 - recall: 0.8876 15360/225000 [=>............................] - ETA: 4:50 - loss: 0.5419 - accuracy: 0.7961 - precision: 0.5465 - recall: 0.8773 16384/225000 [=>............................] - ETA: 4:50 - loss: 0.5324 - accuracy: 0.7995 - precision: 0.5514 - recall: 0.8679 17408/225000 [=>............................] - ETA: 4:48 - loss: 0.5239 - accuracy: 0.8006 - precision: 0.5566 - recall: 0.8597 18432/225000 [=>............................] - ETA: 4:46 - loss: 0.5152 - accuracy: 0.8028 - precision: 0.5617 - recall: 0.8523 19456/225000 [=>............................] - ETA: 4:45 - loss: 0.5069 - accuracy: 0.8058 - precision: 0.5668 - recall: 0.8453 20480/225000 [=>............................] - ETA: 4:44 - loss: 0.4987 - accuracy: 0.8092 - precision: 0.5716 - recall: 0.8380 21504/225000 [=>............................] - ETA: 4:42 - loss: 0.4900 - accuracy: 0.8131 - precision: 0.5762 - recall: 0.8305 22528/225000 [==>...........................] - ETA: 4:41 - loss: 0.4828 - accuracy: 0.8157 - precision: 0.5805 - recall: 0.8225 23552/225000 [==>...........................] - ETA: 4:40 - loss: 0.4751 - accuracy: 0.8192 - precision: 0.5846 - recall: 0.8143 24576/225000 [==>...........................] - ETA: 4:38 - loss: 0.4681 - accuracy: 0.8223 - precision: 0.5885 - recall: 0.8063 25600/225000 [==>...........................] - ETA: 4:37 - loss: 0.4608 - accuracy: 0.8244 - precision: 0.5923 - recall: 0.7987 26624/225000 [==>...........................] - ETA: 4:35 - loss: 0.4536 - accuracy: 0.8272 - precision: 0.5961 - recall: 0.7914 27648/225000 [==>...........................] - ETA: 4:33 - loss: 0.4469 - accuracy: 0.8302 - precision: 0.5997 - recall: 0.7843 28672/225000 [==>...........................] - ETA: 4:32 - loss: 0.4391 - accuracy: 0.8339 - precision: 0.6032 - recall: 0.7772 29696/225000 [==>...........................] - ETA: 4:30 - loss: 0.4317 - accuracy: 0.8372 - precision: 0.6065 - recall: 0.7701